{
  "hash": "cc5e85ae482947ff9cdc3530282058a2",
  "result": {
    "engine": "knitr",
    "markdown": "# Simulated Data {#sec-simul-data}\n\n\n\n:::{.callout-note}\n\nWe follow @Ojeda_2023 to generate data. They kindly provide two functions to simulate binary in the supplementary materials of their article. We adapt their codes to generate the first 12 scenarios from their article.\n\nWe add another type of scenarios to generate the data, so that the predictor is no longer linear.\n\n:::\n\n\n:::{.callout-warning}\n\n## Code Availability\n\nThe functions used to generate data are saved in `../scripts/functions/simul-data.R`. They will be used in other chapters.\n\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\ncolour_samples <- c(\n  \"Train\" = \"#0072B2\",\n  \"Validation\" = \"#009E73\",\n  \"Calibration\" = \"#CC79A7\",\n  \"Test\" = \"#D55E00\"\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"definition of the `theme_paper()` function (for ggplot2 graphs)\"}\n#' Theme for ggplot2\n#'\n#' @param ... arguments passed to the theme function\n#' @export\n#' @importFrom ggplot2 element_rect element_text element_blank element_line unit\n#'   rel\ntheme_paper <- function (...) {\n  ggthemes::theme_base() +\n    theme(\n      legend.background = element_rect(\n        fill = \"transparent\", linetype=\"solid\", colour =\"black\"),\n      legend.position = \"bottom\",\n      legend.direction = \"horizontal\",\n      legend.box = \"horizontal\",\n      legend.key = element_blank()\n    )\n}\n```\n:::\n\n\n\n\n\n## Functions\n\nWe load the functions from [Chapter -@sec-target-distributions] to subsample from a dataset so that the true probability follows a beta distribution.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ks)\nsource(\"../scripts/functions/subsample_target_distribution.R\")\n```\n:::\n\n\n\n\n\n\nThe `simulate_data()`{.R} function generates data for one of the 12 first scenarios described in the article or one of our additional 4 scenarios. This is a helper function that is called in the second one, `simulate_data_wrapper()`{.R} which generates datasets.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n#' Simulates train/validation/calibration/test\n#'\n#' @details\n#' This function is a modified version of the function 'simulateData' in the\n#' R script 'functions-for-calibrating-random-forests.R' provided in the\n#' supplementary material of  Dankowski, T., & Ziegler, A. (2016). Calibrating\n#' random forests for probability estimation. Statistics in medicine, 35(22),\n#' 3949-3960.\n#'\n#' @param n_num number of numerical covariates\n#' @param add_categ if `TRUE`, add 5 categorical variables\n#' @param coeff vector of coefficients (of length n_num + 5)\n#' @param n_noise number of noise variables (drawn from N(0,1))\n#' @param mean_num vector of mean for the numerical variables\n#' @param sd_num vector of standard deviations for the numerical variables\n#' @param size_train size for the train set\n#' @param size_valid size for the validation set\n#' @param size_calib size for the calibration set\n#' @param size_test size for the test set\n#' @param transform_probs if `TRUE`, the true probability is taken to the power of 3\n#' @param linear_predictor if `TRUE`, the predictor of the true probability is a\n#'  linear combination of the covariates. Otherwise, the squared term for x1 is\n#'  added, as well as an interaction term between x2 and x3 (`n_num` thus need\n#'  to be at least 3).\n#' @param seed desired seed (default to `NULL`)\n#' @param linear_predictor_factor if `transform_probs = TRUE`, scalar used to\n#'  draw more observation before subsampling. Default to 3 (a sample 3 times\n#'  larger than `the size of the samples will first be generated before\n#'  subsampling so that the true probability follows a Beta(2,2).\n#'\n#' @returns A list with the following components:\n#'  - train: train set\n#'  - valid: validation set\n#'  - calib: calibration set\n#'  - test: test set\n#'  - probs_train: true probabilities for binary event in train set\n#'  - probs_valid: true probabilities for binary event in validation set\n#'  - probs_calib: true probabilities for binary event in calibration set \n#'  - probs_test: true probabilities for binary event in test set\nsimulate_data <- function(n_num = 2,\n                          add_categ = FALSE,\n                          coeff,\n                          n_noise = 0,\n                          mean_num,\n                          sd_num,\n                          size_train,\n                          size_valid,\n                          size_calib,\n                          size_test,\n                          transform_probs = FALSE,\n                          linear_predictor = TRUE,\n                          linear_predictor_factor = 3,\n                          seed = NULL) {\n\n  n_obs <- size_train + size_valid + size_calib + size_test\n  if (linear_predictor == FALSE) {\n    n_obs <- n_obs * linear_predictor_factor\n  }\n\n  if (!is.null(seed)) {\n    set.seed(seed)\n  }\n\n  # Numerical covariates\n  covariates <- map2(\n    .x = mean_num,\n    .y = sd_num,\n    .f = ~rnorm(n = n_obs, mean = .x, sd = .y)\n  )\n  names(covariates) <- str_c(\"x\", 1:n_num)\n  covariates <- as_tibble(covariates)\n\n  # Categorical covariates\n  if (add_categ == TRUE) {\n    x_c1 <- base::sample(c(0, 1), n_obs, replace = TRUE)\n    x_c2 <- base::sample(c(0, 1), n_obs, replace = TRUE)\n    x_c3 <- base::sample(c(1, 2, 3), n_obs, replace = TRUE)\n    x_c4 <- base::sample(c(1, 2, 3, 4), n_obs, replace = TRUE)\n    x_c5 <- base::sample(c(1, 2, 3, 4, 5), n_obs, replace = TRUE)\n\n    categ_covariates <- tibble(x_c1, x_c2, x_c3, x_c4, x_c5)\n    colnames(categ_covariates) <- str_c(\"x\", (n_num + 1):(n_num + 5))\n    covariates <- bind_cols(covariates, categ_covariates)\n  }\n\n  if (linear_predictor == TRUE) {\n    # Linear predictor\n    eta <- as.matrix(covariates) %*% coeff\n  } else {\n    if (n_num < 3) stop(\"If linear_predictor=TRUE, n_num must be greater than 2\")\n    eta <- as.matrix(covariates) %*% coeff +\n      covariates$x1^2 + covariates$x2^2 * covariates$x3\n  }\n\n  # True probability\n  true_prob <- as.numeric(1 / (1 + exp(-eta)))\n  if (transform_probs) true_prob <- true_prob^3\n\n  # Observed event\n  y <- rbinom(n_obs, size = 1, prob = true_prob)\n\n  # Create dataset with observed event and covariates\n  tb <- tibble(y, covariates)\n\n  if (linear_predictor == FALSE) {\n    # We would like the probabilities to be distributed as a Beta(2,2)\n    tb <- tb |> mutate(p = true_prob)\n    tb <- subset_target(\n      data = tb,\n      probs_name = \"p\",\n      target_fun = function(x) dbeta(x,2,2),\n      iter = 1, draw = FALSE,\n      seed = seed,\n      verbose = FALSE\n    )\n    n_obs <- size_train + size_calib + size_valid + size_test\n    if (nrow(tb) < n_obs) {\n      stop(\n        str_c(\"The number of observation generated is lower than the \",\n              \"desired number. Increase `linear_predictor_factor`.\")\n      )\n    }\n    true_prob <- tb$p[1:n_obs]\n    tb <- tb |> select(-p) |> dplyr::slice_head(n = n_obs)\n  }\n\n\n  # Noise variables\n  if (n_noise > 0) {\n    noise <- matrix(\n      rnorm(n_noise * n_obs, mean = 0, sd = 1),\n      ncol = n_noise,\n      nrow = n_obs,\n      byrow = FALSE\n    ) |>\n      as_tibble()\n    colnames(noise) <- str_c(\"noise_\", 1:n_noise)\n    tb <- bind_cols(tb, noise)\n  }\n\n  # Split data into train/calib/valid/test\n  tb_train <- tb |> dplyr::slice(1:size_train)\n  true_prob_train <- true_prob[1:size_train]\n  \n  # Validation\n  ind_valid <- (size_train + 1):(size_train + size_valid)\n  tb_valid <- tb |> dplyr::slice(ind_valid)\n  true_prob_valid <- true_prob[ind_valid]\n  \n  # Calibration\n  ind_calib <- (size_train + size_valid + 1):(size_train + size_valid + size_calib)\n  tb_calib <- tb |> dplyr::slice(ind_calib)\n  true_prob_calib <- true_prob[ind_calib]\n  \n  # Test\n  ind_test <- (size_train + size_valid + size_calib + 1):n_obs\n  tb_test <- tb |> dplyr::slice(ind_test)\n  true_prob_test <- true_prob[ind_test]\n  \n  list(\n    train = tb_train,\n    valid = tb_valid,\n    calib = tb_calib,\n    test = tb_test,\n    probs_train = true_prob_train,\n    probs_valid = true_prob_valid,\n    probs_calib = true_prob_calib,\n    probs_test = true_prob_test\n  )\n}\n```\n:::\n\n\n\n\n\nThe `simulate_data_wrapper()`{.R} is the one we call to generate a dataset, given a scenario and a seed.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n#' Generates data for a given simulation scenario.\n#'\n#' @details\n#' Wrapper of 'simulate_data' function that generates the data for a given\n#' simulation scenario.\n#'\n#' @param scenario simulation scenario number.\n#' @param params_df data frame containing the parameters to be passed to the\n#'  `simulate_data` for each simulation scenario.\n#' @param repn Number of current replication to be generated for the given\n#'  simulation scenario.\n#'\n#' @returns A list with the following components:\n#'  - scenario: the scenario ID\n#'  - params_df: the parameters used for the data generation for the given\n#'               scenario.\n#'  - repn: Number of current replication that was generated for the given\n#'          simulation scenario.\n#'  - data: list with the simulated data (train, valid, test, probs_train,\n#'          probs_valid and probs_test)\n#'          see result of `simulate_data()`.\nsimulate_data_wrapper <- function(scenario, params_df, repn) {\n  params <- params_df[params_df[[\"scenario\"]] == scenario, ]\n  if(nrow(params) != 1) stop(\"More than one row from params_df chosen\")\n\n  seed_for_repn <- pull(params, \"seed\") + repn\n\n  args <- list(\n    coeff = params |> pull(\"coefficients\") |> pluck(1),\n    n_num = params |> pull(\"n_num\"),\n    add_categ = params |> pull(\"add_categ\"),\n    n_noise = params |> pull(\"n_noise\"),\n    mean_num = params |> pull(\"mean_num\") |> pluck(1),\n    sd_num = params |> pull(\"sd_num\") |> pluck(1),\n    size_train = params |> pull(\"size_train\"),\n    size_valid = params |> pull(\"size_valid\"),\n    size_calib = params |> pull(\"size_calib\"),\n    size_test = params |> pull(\"size_test\"),\n    transform_probs = params |> pull(\"transform_probs\"),\n    linear_predictor = params |> pull(\"linear_predictor\"),\n    seed = seed_for_repn\n  )\n  sim_data <- do.call(\"simulate_data\", args)\n\n  list(\n    scenario = scenario,\n    params_df = params,\n    repn = repn,\n    data = sim_data\n  )\n\n}\n```\n:::\n\n\n\n\n\n## Scenarios\n\nLet us define the 12 first scenarios, using the code provided in @Ojeda_2023.\n\n- **DGP 1**:\n\n  - **Scenario 1**: basic scenario with two continuous predictors, without noise variable\n  - **Scenarios 2, 3, 4**: same as 1 but with noise variables (10, 50, 100)\n\n- **DGP 2**:\n\n  - **Scenarios 5 to 8**: similar to 1 to 4 but with right-skewed true probability distribution (true probability taken to the power of 3)\n\n- **DGP 3**:\n\n  - **Scenarios 9 to 12**: similar to 1 to 4 but with ten predictors instead of two (5 numerical and 5 categorical)\n\nWe add four other scenarios, in which the predictor is nonlinear:\n\n- **DGP 4**:\n\n  - **Scenarios 13 to 16**: similar to 1 to 4 but with 3 covariates instead of 2 and with a nonlinear predictor which also contains an interaction term ($\\eta = \\alpha _1x_1 + \\alpha_2 x_2 + \\alpha_3 x_3 + \\beta x_1^2 + \\gamma x_2 \\times x_3$). In addition, the distribution of the true probabilities of the observed data follows a Beta(2,2) distribution.\n\nThe desired number of replications for each scenario needs to be set:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrepns_vector <- 1:100\n```\n:::\n\n\n\n\n\nWe set the different parameters for each scenario.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Coefficients beta\ncoefficients <- list(\n  # First category (baseline, 2 covariates)\n  c(0.5, 1),  # scenario 1, 0 noise variable\n  c(0.5, 1),  # scenario 2, 10 noise variables\n  c(0.5, 1),  # scenario 3, 50 noise variables\n  c(0.5, 1),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  c(0.5, 1),  # scenario 5, 0 noise variable\n  c(0.5, 1),  # scenario 6, 10 noise variables\n  c(0.5, 1),  # scenario 7, 50 noise variables\n  c(0.5, 1),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  c(0.5, 1, .3),  # scenario 5, 0 noise variable\n  c(0.5, 1, .3),  # scenario 6, 10 noise variables\n  c(0.5, 1, .3),  # scenario 7, 50 noise variables\n  c(0.5, 1, .3)  # scenario 8, 100 noise variables\n)\n\n# Mean parameter for the normal distribution to draw from to draw num covariates\nmean_num <- list(\n  # First category (baseline, 2 covariates)\n  rep(0, 2),  # scenario 1, 0 noise variable\n  rep(0, 2),  # scenario 2, 10 noise variables\n  rep(0, 2),  # scenario 3, 50 noise variables\n  rep(0, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(0, 2),  # scenario 5, 0 noise variable\n  rep(0, 2),  # scenario 6, 10 noise variables\n  rep(0, 2),  # scenario 7, 50 noise variables\n  rep(0, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3)\n)\n# Sd parameter for the normal distribution to draw from to draw num covariates\nsd_num <- list(\n  # First category (baseline, 2 covariates)\n  rep(1, 2),  # scenario 1, 0 noise variable\n  rep(1, 2),  # scenario 2, 10 noise variables\n  rep(1, 2),  # scenario 3, 50 noise variables\n  rep(1, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(1, 2),  # scenario 5, 0 noise variable\n  rep(1, 2),  # scenario 6, 10 noise variables\n  rep(1, 2),  # scenario 7, 50 noise variables\n  rep(1, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3)\n)\n\nparams_df <- tibble(\n  scenario = 1:16,\n  coefficients = coefficients,\n  n_num = c(rep(2, 8), rep(5, 4), rep(3, 4)),\n  add_categ = c(rep(FALSE, 8), rep(TRUE, 4), rep(FALSE, 4)),\n  n_noise = rep(c(0, 10, 50, 100), 4),\n  mean_num = mean_num,\n  sd_num = sd_num,\n  size_train = rep(10000, 16),\n  size_valid = rep(10000, 16),\n  size_calib = rep(10000, 16),\n  size_test = rep(10000, 16),\n  transform_probs = c(rep(FALSE, 4), rep(TRUE, 4), rep(FALSE, 4), rep(FALSE, 4)),\n  linear_predictor = c(rep(TRUE, 12), rep(FALSE, 4)),\n  seed = 202105\n)\nrm(coefficients, mean_num, sd_num)\n```\n:::\n\n\n\n\n\n\n## Example\n\nLet us draw a sample of 10,000 observations in each set (train, calibration, validation, test), for each scenario. We can then plot the histogram of the true probabilities in each sample (@fig-hist-true-prob-ojeda).\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npar(mfrow = c(16, 4), mar = c(2, 2, 2, 2))\nfor (scenario in 1:16) {\n  simu_data <- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repns_vector[1] # only one replication here\n  )\n  colour_samples <- c(\n    \"Train\" = \"#0072B2\",\n    \"Calib\" = \"#CC79A7\",\n    \"Valid\" = \"#009E73\",\n    \"Test\" = \"#D55E00\"\n  )\n  for (sample in c(\"train\", \"valid\", \"calib\", \"test\")) {\n    if (sample == \"train\") {\n      true_prob <- simu_data$data$probs_train\n      i_scores <- 1\n    } else if (sample == \"valid\") {\n      true_prob <- simu_data$data$probs_valid\n      i_scores <- 2\n    } else if (sample == \"calib\") {\n      true_prob <- simu_data$data$probs_calib\n      i_scores <- 3\n    } else {\n      true_prob <- simu_data$data$probs_test\n      i_scores <- 4\n    }\n    hist(\n      true_prob,\n      breaks = seq(0, 1, by = .05),\n      col = colour_samples[i_scores],\n      border = \"white\",\n      xlab = \"p\", ylab = \"\",\n      main = str_c(\n        \"Scen. \", scenario, \", \", c(\"Train\", \"Valid\", \"Calib\", \"Test\")[i_scores]\n      ),\n      xlim = c(0, 1)\n    )\n  }\n}\n```\n\n::: {.cell-output-display}\n![Histogram of true probabilities for each scenario](simul-data_files/figure-html/fig-hist-true-prob-ojeda-1.png){#fig-hist-true-prob-ojeda width=768}\n:::\n:::\n\n\n\n\n\nFor each group of scenarios, the only thing that varies is the number of noise variables. This has no impact on the distribution of the true probability. Hence, we can create a simple figure with the distribution of the true probability for each group of scenario.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Only on Train test, for each category of scenarios.\"}\nsave_graph <- FALSE\n\nif (save_graph) {\n  cairo_pdf(\n    \"../figs/sim-data-hist-categories.pdf\", \n    width = 8, height = 2\n  )\n}\n\npar(mfrow = c(1, 4), mar = c(4.1, 3.1, 2.1, 1.1))\nfor (i_dgp in 1:4) {\n  scenario <- c(1, 5, 9, 13)[i_dgp]\n  simu_data <- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repns_vector[1] # only one replication here\n  )\n  \n  true_prob <- simu_data$data$probs_test\n  title <- str_c(\"DGP \", i_dgp)\n  \n  hist(\n    true_prob,\n    breaks = seq(0, 1, by = .05),\n    # col = ,\n    # border = \"white\",\n    xlab = \"p\", ylab = \"\",\n    main = title,\n    xlim = c(0, 1)\n  )\n}\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in ks.test.default(probs_01, fun): ties should not be present for the\none-sample Kolmogorov-Smirnov test\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Only on Train test, for each category of scenarios.\"}\nif (save_graph) dev.off()\n```\n\n::: {.cell-output-display}\n![Distribution of the underlying probabilities in the different categories of scenarios.](simul-data_files/figure-html/fig-hist-underlying-prob-1.png){#fig-hist-underlying-prob width=672}\n:::\n:::\n",
    "supporting": [
      "simul-data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}