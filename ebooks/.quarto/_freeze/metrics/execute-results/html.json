{
  "hash": "772920574e9c68e847dbc41aac5a134c",
  "result": {
    "engine": "knitr",
    "markdown": "# Metrics {#sec-metrics}\n\n::: {.hidden}\n$\\DeclareMathOperator{\\g}{g}$\n:::\n\n:::{.callout-note}\n\nThis chapter introduces the functions used to compute various metrics, including performance, calibration, and the divergence between model-predicted scores and true probabilities' distribution.\n\n:::\n\n\n:::{.callout-warning}\n\nThe codes defined here are saved in `../scripts/functions/metrics.R`.\n\n:::\n\n\n## Performance and Calibration Metrics\n\n\nTo measure performance, we chose to compute:\n\n- the true Mean Squared Error (MSE): the average of the quadratic difference between predicted scores and true probabilities (only if the true probabilities are available thanks to the knowledge of the PGD)\n- the accuracy, which gives the proportion of correctly predicted instances; we use a probability threshold of 0.5)\n- the AUC.\n\n\nTo measure calibration, we compute two metrics:\n\n- the Brier score (@brier_1950)\n- the Integrated Calibration Index (@Austin_2019).\n\n::: {.callout-tip}\n\n### Brier Score\n\nGiven a sample size $n$, the Brier Score @brier_1950, is expressed as:\n$$\n\\begin{equation}\n\\text{BS} = \\frac{1}{n}\\sum_{i=1}^{n} \\big(\\hat{s}(\\mathbf{x}_i) - d_i\\big)^{2}\\enspace ,\n\\end{equation}\n$$ {#eq-brier-score}\n\nwhere $\\hat{s}(\\mathbf{x}_i)$ and $d_i \\in \\{0,1\\}$ are the predicted score and observed event, respectively, for observation $i$.\n\n:::\n\n::: {.callout-tip}\n\n### Integrated Calibration Index \n\nInstead of defining bins, the Integrated Calibration Index or ICI (@Austin_2019) measures calibration using a local estimation (loess if the number of observation is lower than 1000 ; using a GAM otherwise).\n\nThe occurrence of the binary event is regressed on the predicted scores, employing either locally estimated scatterplot smoothing (LOESS) when the number of observations is small ($n < 1000$) or cubic regression splines for larger datasets. The ICI is defined as\n$$\n\\begin{equation}\n    \\text{ICI} = \\int_{0}^{1} f(p)  \\phi(p)\\, dp\n\\end{equation}\n$$ {#eq-ici}\nwhere $f(p) = | p - \\g(p) |$ is the absolute difference between the calibration curve and the bisector where $p$ denotes a predicted score (_i.e._, $p=\\hat{s}(\\mathbf{x})$) and $\\g(p)$ is the value of the calibration curve at this predicted score. The density function of the distribution of predicted scores is denoted $\\phi(p)$. \n\n\n:::\n\nAll these metrics are computed in a function we name `compute_metrics()`{.R} which takes three arguments:\n\n- `obs`: a vector of observed binary events\n- `scores`: a vector of predicted scores\n- `true_probas`: if available, a vector of true probabilities from the PGD (to compute MSE).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#' Brier Score\n#'\n#' The Brier Score \\citep{brier_1950}, is expressed as: \\deqn{\\text{BS} =\n#' \\frac{1}{n}\\sum_{i=1}^{n} \\big(\\hat{s}(\\mathbf{x}_i) - d_i\\big)^{2}} where\n#' \\eqn{d_i \\in \\{0,1\\}} is the observed event for observation \\eqn{i}.\n#'\n#' @param scores vector of scores\n#' @param obs vector of observed binary events\n#'\n#' @references Brier, G. W. (1950). Verification of forecasts expressed in terms\n#' of probability. Monthly Weather Review 78: 1â€“3.\n#'\n#' @export\nbrier_score <- function(obs, scores) mean((scores - obs)^2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#' Computes the calibration metrics for a set of observed and predicted\n#' probabilities\n#'\n#' @returns\n#' \\itemize{\n#'   \\item \\code{mse}: True Mean Squared Error based on true probability.\n#'   \\item \\code{acc}: accuracy with a .5 probability threshold.\n#'   \\item \\code{AUC}: Area Under the ROC Curve.\n#'   \\item \\code{brier}: Brier score.\n#'   \\item \\code{ici}: Integrated Calibration Index.\n#' }\n#'\n#' @param obs observed events\n#' @param scores predicted scores\n#' @param true_probas true probabilities from the PGD (to compute MSE)\n#'\n#' @importFrom purrr map\n#' @importFrom tibble tibble\n#' @importFrom dplyr bind_rows\n#'\n#' @export\ncompute_metrics <- function(obs,\n                            scores,\n                            true_probas = NULL) {\n\n  # True MSE\n  if (!is.null(true_probas)) {\n    mse <- mean((true_probas - scores)^2)\n  } else {\n    mse <- NA\n  }\n\n  # True MAE\n  if (!is.null(true_probas)) {\n    mae <- mean(abs(true_probas - scores))\n  } else {\n    mae <- NA\n  }\n\n  # AUC\n  AUC <- pROC::auc(obs, scores, levels = c(\"0\", \"1\"), quiet = TRUE) |>\n    as.numeric()\n\n  # Brier Score\n  brier <- brier_score(obs = as.numeric(as.character(obs)), scores = scores)\n  # gmish::brier(pred = scores, obs = obs) #same results\n\n  # ICI\n  ici_quiet <- purrr::quietly(gmish::ici)\n  ici <- ici_quiet(pred = scores, obs = as.numeric(as.character(obs)))\n  ici <- ici$result\n\n  # Accuracy\n  pred_class <- ifelse(scores > .5, yes = 1, no = 0)\n  acc <- sum(diag(table(obs = obs, pred = pred_class))) / length(scores)\n\n  tibble(\n    mse = mse,\n    mae = mae,\n    acc = acc,\n    AUC = AUC,\n    brier = brier,\n    ici = ici\n  )\n}\n```\n:::\n\n\n\n\n## Dispersion Metrics\n\nWe compute the Kullback-Leibler divergence @Kullback_1951 between the distribution of the estimated scores and the distribution of the true probabilities. Denoting \\(Q\\) the distribution of the scores and \\(P\\) the distribution of the true probabilities, the Kullback Leibler divergence of $Q$ with respect to $P$ is :%\n\\begin{equation}\nD_{KL}(Q || P) = \\sum_{i} Q(i) \\log \\frac{Q(i)}{P(i)}.\n\\end{equation}\n\nThe distributions both need to be discretized. We divide the segment \\([0,1]\\) into \\(m\\) bins.\n\nIn the `dispersion_metrics()`{.R} that we define to that end, we consider $m=20$ bins. We also consider switching the reference distribution (where $Q$ denotes the distribution of the true probabilities and $P$ denotes the distribution of scores).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#' Computes the dispersion metrics for a set of observed and predicted\n#' probabilities\n#'\n#' @returns\n#' \\itemize{\n#'   \\item \\code{inter_quantile_25_75}: Difference of inter-quantile between 25% and 75%\n#'   \\item \\code{inter_quantile_10_90}: Difference of inter-quantile between 10% and 90%\n#'   \\item \\code{KL_20_true_probas}: KL of of predicted probabilities w.r. to true probabilities with 20 bins\n#'   \\item \\code{KL_20_scores}: KL of of true probabilities w.r. to predicted probabilities with 20 bins\n#'   \\item \\code{ind_cov}: Difference between the variance of true probabilities and the covariance between true probabilities and predicted scores\n#' }\n#'\n#' @param true_probas true probabilities from simulations\n#' @param scores predicted scores\n#'\ndispersion_metrics <- function(true_probas, scores){\n\n  # Inter-quantiles\n  inter_q_80 <- diff(quantile(scores, c(.9, .1))) /\n    diff(quantile(true_probas, c(.9, .1)))\n  inter_q_50 <- diff(quantile(scores, c(.75,.25))) /\n    diff(quantile(true_probas, c(.75, .25)))\n\n  # KL divergences\n  m <- 20 # Number of bins\n  h_p <- hist(true_probas,breaks = seq(0, 1, length = m + 1), plot = FALSE)\n  h_phat <- hist(scores, breaks = seq(0, 1, length = m + 1), plot = FALSE)\n  # Densities\n  h1 <- rbind(h_phat$density / m,h_p$density / m) # Reference : true probabilities\n  h2 <- rbind(h_p$density / m, h_phat$density / m) # Reference : predicted scores\n  KL_20_true_probas <- distance(\n    h1, method = \"kullback-leibler\", unit = \"log2\", mute.message = TRUE)\n  KL_20_scores <- distance(\n    h2, method = \"kullback-leibler\", unit = \"log2\", mute.message = TRUE)\n\n  # Indicator of the difference between variance and covariance\n  var_p <- var(true_probas)\n  cov_p_phat <- cov(true_probas, scores)\n  ind_cov <- abs(cov_p_phat - var_p)\n\n  # Collection\n  dispersion_metrics <- tibble(\n    \"inter_quantile_25_75\" = as.numeric(inter_q_50),\n    \"inter_quantile_10_90\" = as.numeric(inter_q_80),\n    \"KL_20_true_probas\" = as.numeric(KL_20_true_probas),\n    \"KL_20_scores\" = as.numeric(KL_20_scores),\n    \"ind_cov\" = ind_cov\n    )\n\n  dispersion_metrics\n}\n```\n:::\n\n\nLastly, we estimate $\\mathbb{P}(q_1 < \\hat{s}(\\mathbf{x}) < q_2)$, with $q_2 = 1-q_1$, for different values of $q_1$ and $q_2$. To do so, we simply calculate the sample proportion of scores between $q_1$ and $q_2$. The `prop_btw_quantiles()`{.R} does it.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#' Computes \\hat{P}(q_1 < s < q_2)\n#'\n#' @param s scores\n#' @param q1 lower quantile\n#' @param q2 upper quantile (default to 1-q2)\nprop_btw_quantiles <- function(s, q1, q2 = 1 - q1) {\n  tibble(q1 = q1, q2 = q2, freq = mean(s < q2 & s > q1))\n}\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}